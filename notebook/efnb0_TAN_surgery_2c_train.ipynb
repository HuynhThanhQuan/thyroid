{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAcQibGtx8AO"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13216,
     "status": "ok",
     "timestamp": 1706580168976,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "W0MG0K37Q-ci"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "executionInfo": {
     "elapsed": 3417,
     "status": "ok",
     "timestamp": 1706580172391,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "JYrRst4JbHfh",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import windows_utils_hf as util\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1706580174276,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "kOWt0keNftSa"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import re\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1706580175203,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "VWot6zZnPpH_"
   },
   "outputs": [],
   "source": [
    "# Import utility functions\n",
    "from cjm_pandas_utils.core import markdown_to_pandas\n",
    "from cjm_pil_utils.core import resize_img\n",
    "from cjm_pytorch_utils.core import set_seed, pil_to_tensor, tensor_to_pil, get_torch_device, denorm_img_tensor\n",
    "\n",
    "# Import HuggingFace Datasets dependencies\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO6v2uo7yAKn"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706580175203,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "5aArhhq4ewxv"
   },
   "outputs": [],
   "source": [
    "repo_fp = Path('../data/')\n",
    "tan_fp = repo_fp / 'Tanzania-Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me8PCmk3O8Zw"
   },
   "source": [
    "## TAN Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_data = pd.read_csv('../metadata/TAN_surgery_2c.csv', index_col=0)\n",
    "tan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_data['new_label'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_data[['patient_id', 'new_label']].drop_duplicates()['new_label'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldk = 'fold_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_sum = tan_data[['patient_id', 'new_label']].drop_duplicates()\n",
    "fig, axs = plt.subplots(1,2,figsize=(12,5))\n",
    "tan_sum['new_label'].plot(kind='hist', bins=20, title='label',ax=axs[0], grid=True)\n",
    "tan_sum['new_label'].value_counts(dropna=False, normalize=True).fillna('NA').sort_index().plot(kind='pie', autopct='%.2f%%', ax=axs[1])\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_data.groupby([foldk,'new_label'])['patient_id'].nunique().to_frame().reset_index().pivot_table(index=foldk, columns='new_label', values='patient_id').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_data.groupby([foldk,'new_label'])['image_path'].nunique().to_frame().reset_index().pivot_table(index=foldk, columns='new_label', values='image_path').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = tan_data[['image_path', 'new_label', foldk]]\n",
    "img_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I-ArNLvPD0V"
   },
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1706583480466,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "uKP61nSKfP1L"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1706583481563,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "qDgJbDK4dssQ"
   },
   "outputs": [],
   "source": [
    "img_path = img_ds.iloc[0]['image_path']\n",
    "# img = read_image(img_path)\n",
    "img = Image.open(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706583497937,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "UHzo1Gr3rK9t"
   },
   "outputs": [],
   "source": [
    "# prompt: generate train and test transform\n",
    "\n",
    "\n",
    "# Create transforms for train and test data\n",
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize(224, antialias=True),\n",
    "    v2.RandomCrop(224),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    # v2.AutoAugment(v2.AutoAugmentPolicy.CIFAR10), # [v2.AutoAugmentPolicy.CIFAR10, v2.AutoAugmentPolicy.IMAGENET, v2.AutoAugmentPolicy.SVHN]\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize(224, antialias=True),\n",
    "    v2.CenterCrop(size=224),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dF9yYWqdtat"
   },
   "source": [
    "### Inspect train and test transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "executionInfo": {
     "elapsed": 7034,
     "status": "ok",
     "timestamp": 1706583508257,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "6e8IaKD6eADu",
    "outputId": "7d547a0e-3799-434a-f1d7-59a9ed963660"
   },
   "outputs": [],
   "source": [
    "train_outs = [train_transform(img) for i in range(5)]\n",
    "test_out = test_transform(img)\n",
    "helpers.plot([img, test_out] + train_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kG8MBKAHFvYF"
   },
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1706583523732,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "FG6MJ-g1rZih"
   },
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUYJUO9nfYSq"
   },
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1706583529866,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "XAFEDCJfhzn0"
   },
   "outputs": [],
   "source": [
    "# prompt: i need pytorch dataset that read from dataframe\n",
    "class TANThyroidDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe['image_path'][idx]\n",
    "        label = self.dataframe['new_label'][idx]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706583531383,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "t5c5FKDop8Ld"
   },
   "outputs": [],
   "source": [
    "train_df = img_ds[img_ds[foldk]=='train'].reset_index(drop=True)\n",
    "# val_df = img_ds[img_ds[foldk]=='val'].reset_index(drop=True)\n",
    "test_df = img_ds[img_ds[foldk]=='test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1706583532543,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "ktqjvM7fp06a"
   },
   "outputs": [],
   "source": [
    "trainset = TANThyroidDataset(train_df, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1706583534512,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "K4VmapsTrc4p"
   },
   "outputs": [],
   "source": [
    "# valset = TANThyroidDataset(val_df, transform=test_transform)\n",
    "# valoader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "#                                           shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1706583534512,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "6ryfrElarmi4"
   },
   "outputs": [],
   "source": [
    "testset = TANThyroidDataset(test_df, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se2OgWzZPPg9"
   },
   "source": [
    "##  Inspect Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1706583538472,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "dU21Z1fEP9WQ"
   },
   "outputs": [],
   "source": [
    "norm_stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 3186,
     "status": "ok",
     "timestamp": 1706583542196,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "XjE6BFieQUQf",
    "outputId": "360f53e4-bbef-4395-ba81-b60be918053d"
   },
   "outputs": [],
   "source": [
    "# Select a random item from the dataset\n",
    "import numpy as np\n",
    "item_path = np.random.choice(train_df['image_path'])\n",
    "print(item_path)\n",
    "sample_img = Image.open(item_path)\n",
    "# Display the image\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "executionInfo": {
     "elapsed": 30660,
     "status": "error",
     "timestamp": 1706583581058,
     "user": {
      "displayName": "Thanh Quan Huỳnh (Quan Huỳnh)",
      "userId": "03187563831267744022"
     },
     "user_tz": -420
    },
    "id": "5xFKva8lPWcd",
    "outputId": "9d318a0e-ce3d-41b5-f174-ffdb1033f153"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(trainloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "indx = 0\n",
    "f, axarr = plt.subplots(2, 4, figsize=(12, 8))\n",
    "for r in range(0, 2):\n",
    "  for c in range(0, 4):\n",
    "    img = train_features[indx].squeeze()\n",
    "    label = train_labels[indx]\n",
    "    axarr[r, c].imshow(tensor_to_pil(denorm_img_tensor(img, *norm_stats)))\n",
    "    axarr[r, c].set_title(f'ground: {label}')\n",
    "    indx+=1\n",
    "#tensor_to_pil(denorm_img_tensor(train_dataset[10][0], *norm_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TS3WlecPTCL"
   },
   "source": [
    "## Device and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "\n",
    "    # List information about each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_info = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {gpu_info.name}\")\n",
    "        print(f\"   Compute Capability: {gpu_info.major}.{gpu_info.minor}\")\n",
    "        print(f\"   Total Memory: {gpu_info.total_memory / (1024 ** 3):.2f} GB\\n\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3FPvSCkcATx"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "4nFl8m1jHaE2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt: use tensorboard to log\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('../runs/thyroid_TAN_surgery_2c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_uGUwa_fWFd"
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0l_vCdtqpg4w"
   },
   "outputs": [],
   "source": [
    "# prompt: train this trainloader using efficient-net model. this is classification problem\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0l_vCdtqpg4w"
   },
   "outputs": [],
   "source": [
    "model._fc = nn.Linear(model._fc.in_features, train_df['new_label'].nunique())\n",
    "# model._fc = nn.Linear(model._fc.in_features, 1)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8eq3vULpjOE"
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "best_val_acc = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lePrEdKyggYn"
   },
   "source": [
    "# Criterion, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6v8lsLyCgflr"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.3, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBd16KZXgddp"
   },
   "outputs": [],
   "source": [
    "# AdamW optimizer; includes weight decay for regularization\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, eps=1e-5)\n",
    "\n",
    "# Learning rate scheduler; adjusts the learning rate during training\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=num_epochs*len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_clf(preds_ts, outs_ts):\n",
    "    np_preds = [i.numpy() for i in preds_ts]\n",
    "    np_outs = [i.numpy() for i in outs_ts]\n",
    "    \n",
    "    np_preds = np.array([i for s in np_preds for i in s])\n",
    "    np_outs = np.array([i for s in np_outs for i in s])\n",
    "    assert np_preds.shape == np_outs.shape\n",
    "\n",
    "    print(metrics.classification_report(np_outs, np_preds))\n",
    "\n",
    "    cm = metrics.confusion_matrix(np_outs, np_preds)\n",
    "    d = metrics.ConfusionMatrixDisplay(cm)\n",
    "    d.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqcHDGZOp-4T"
   },
   "outputs": [],
   "source": [
    "def evaluate_dataset(model, ds_loader):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    preds = []\n",
    "    outs = []\n",
    "    for _, (data, target) in enumerate(tqdm(ds_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss += loss.item()\n",
    "        acc += accuracy_score(output.cpu().argmax(dim=1), target.cpu())\n",
    "        preds.append(output.cpu().argmax(dim=1))\n",
    "        outs.append(target.cpu())\n",
    "        \n",
    "    loss /= len(testloader)\n",
    "    acc /= len(testloader)\n",
    "    print('Test Loss: {:.4f} \\tTest Acc: {:.4f}'.format(loss, acc))\n",
    "    report_clf(preds, outs)\n",
    "    return acc,preds, outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tP1uA5UFfM7u"
   },
   "source": [
    "# If exist model, then evaluate before write new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KrcW4hnrQtjX"
   },
   "outputs": [],
   "source": [
    "def run_predict_testset():\n",
    "    test_features, test_labels = next(iter(testloader))\n",
    "    # Make a prediction with the model\n",
    "    class_names = [0,1,2]\n",
    "    with torch.no_grad():\n",
    "        preds = model(test_features.to(device))\n",
    "        #print(preds)\n",
    "        print(f\"Feature batch shape: {test_features.size()}\")\n",
    "        print(f\"Labels batch shape: {test_labels.size()}\")\n",
    "        indx = 0\n",
    "        f, axarr = plt.subplots(3, 3, figsize=(12, 8))\n",
    "        for r in range(0, 3):\n",
    "            for c in range(0, 3):\n",
    "                img_tensor = test_features[indx]\n",
    "                label = class_names[test_labels[indx].numpy()]\n",
    "                print('Label: ', label)\n",
    "                # Scale the model predictions to add up to 1\n",
    "                pred_scores = torch.softmax(preds[indx], dim=0)\n",
    "                # Get the highest confidence score\n",
    "                confidence_score = pred_scores.max()\n",
    "                # Get the class index with the highest confidence score and convert it to the class name\n",
    "                pred_class = class_names[torch.argmax(pred_scores)]\n",
    "                print('Predicted: ', pred_class)\n",
    "                axarr[r, c].imshow(tensor_to_pil(denorm_img_tensor(img_tensor, *norm_stats)))\n",
    "                axarr[r, c].set_title(f\"ground: {label}, pred: {pred_class}, conf: {confidence_score*100:.2f}%\")\n",
    "                indx+=1\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_path = '../model/tan_surgery_2c/efficientnet-b0-clf.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "L1wUMmV8plXI",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reload model\n",
    "model_fp = Path(baseline_model_path)\n",
    "if model_fp.exists():\n",
    "    model.load_state_dict(torch.load(str(model_fp), map_location=torch.device(device)))\n",
    "    best_val_acc, _, _ = evaluate_dataset(model, testloader)\n",
    "    run_predict_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1dkHluorHpv"
   },
   "outputs": [],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uccIKhg4fSbH"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGwUifiR85p5"
   },
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n",
    "#     data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ow2UldDJ8DcT"
   },
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(tqdm(valoader)):\n",
    "#     data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95zVJrcp88ez"
   },
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(tqdm(testloader)):\n",
    "#     data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmIV_fRFsAu-"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_score(output.cpu().argmax(dim=1), target.cpu())\n",
    "    train_loss /= len(trainloader)\n",
    "    train_acc /= len(trainloader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(testloader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += accuracy_score(output.cpu().argmax(dim=1), target.cpu())\n",
    "    val_loss /= len(testloader)\n",
    "    val_acc /= len(testloader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print('Epoch: {} \\tTrain Loss: {:.4f} \\tTrain Acc: {:.4f} \\tVal Loss: {:.4f} \\tVal Acc: {:.4f}'.format(\n",
    "        epoch, train_loss, train_acc, val_loss, val_acc))\n",
    "    writer.add_scalar('Train/Loss', loss.item(), epoch * len(trainloader) + batch_idx)\n",
    "    writer.add_scalar('Train/Accuracy', train_acc, epoch * len(trainloader) + batch_idx)\n",
    "    writer.add_scalar('Validation/Loss', val_loss, epoch * len(testloader) + batch_idx)\n",
    "    writer.add_scalar('Validation/Accuracy', val_acc, epoch * len(testloader) + batch_idx)\n",
    "\n",
    "    # if val_acc > best_val_acc:\n",
    "    best_val_acc = val_acc\n",
    "    evaluate_dataset(model, testloader)\n",
    "    print(f'Better result, val: {best_val_acc}')\n",
    "    torch.save(model.state_dict(), baseline_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsReyx8Gk1z7"
   },
   "outputs": [],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kjpd-yH7Xi9"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMEjE7Mlrf4u"
   },
   "outputs": [],
   "source": [
    "evaluate_dataset(model, testloader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "QB4SD4IG4NO2",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMcbGaJiWva82whQhAK1Dr/",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
