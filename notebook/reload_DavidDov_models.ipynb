{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cc483b-e22c-4f3c-8411-c4b73b0bb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc886cfc-4423-43f7-ad88-489189b270c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC = '../repo/DavidDov/tele_cyto_models/hub/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def13385-ca23-40dc-b589-182944a7194a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vgg11_bn-6002323d.pth', 'mobilenet_v2-b0353104.pth']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64316ff0-4079-48f0-9c7a-6edd13077987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(os.path.join(LOC, 'vgg11_bn-6002323d.pth'))\n",
    "checkpoint = torch.load(os.path.join(LOC, 'mobilenet_v2-b0353104.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812c10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class VGG11Model(nn.Module):\n",
    "    \"\"\"VGG11 model class.\n",
    "\n",
    "    Attributes:\n",
    "        biases (torch.nn.Parameter): TODO: add description.\n",
    "        vgg_features (torch.nn.Module): VGG feature map function.\n",
    "        features (torch.nn.Sequential): hidden layers.\n",
    "        classifier (torch.nn.Sequential): classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, params: dict):\n",
    "        \"\"\"VGG11 model class constructor. \n",
    "        \n",
    "        Args:\n",
    "            params (dict): hyperparameters.\n",
    "        \"\"\"\n",
    "        super(VGG11Model, self).__init__()\n",
    "        \n",
    "        # Output thresholds for Bethesda score prediction. Selected such that sigmoid(t1)-sigmoid(t2) = sigmoid(t2)-sigmoid(t3) = sigmoid(t3)-sigmoid(t4) = 0.2.\n",
    "        if params['trainable_biases']:\n",
    "            self.biases = nn.Parameter(torch.tensor([1.386, 0.405, -0.405, -1.386]))\n",
    "        else:\n",
    "            self.biases = torch.tensor([1.386, 0.405, -0.405, -1.386], requires_grad=False)\n",
    "        \n",
    "        # Load VGG11 model (without ImageNet pretraining).\n",
    "        vgg11 = models.vgg11_bn(pretrained=params['pretrain'])\n",
    "        \n",
    "        # Load VGG11 weights. TODO(dd208): explain where the checkpoint comes from. TODO: Need to uncomment!\n",
    "        # vgg11.load_state_dict(torch.load('../params_soft_link/vgg11_bn-6002323d.pth'))\n",
    "        \n",
    "        # Define VGG11 feature extractor.\n",
    "        self.vgg_features = vgg11.features        \n",
    "        # Further feature extraction.\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4 , 16), #(512, 16)\n",
    "            nn.BatchNorm1d(16), #nn.Dropout(),\n",
    "            nn.ReLU(True))        \n",
    "        # Final classifier. \n",
    "        self.classifier = nn.Sequential( \n",
    "            nn.BatchNorm1d(16), #nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 1))\n",
    "        \n",
    "               \n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"VGG11 classifier forward pass.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): [B, P, C, H, W] torch.tensor input. (B=batch, P=patches, CHW=image dims).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: _description_\n",
    "        \"\"\"\n",
    "        # Reshape input: [B, P, C, H, W] -> [B*P, C, H, W].\n",
    "        z = z.view([z.shape[0]*z.shape[1]] + list(z.shape[2:]))                              \n",
    "        # Extract VGG features: [B*P, C, H, W] -> [B*P, 512, 4, 4].\n",
    "        z = self.vgg_features(z)     \n",
    "                     \n",
    "        # Reshape: [B*P, 512, 4, 4] -> [B*P, 512*4*4]\n",
    "        z = z.view(z.shape[0], -1)  \n",
    "        # Further feature extraction: [B*P, 512*4*4] -> [B*P, 16].\n",
    "        z = self.features(z)        \n",
    "\n",
    "        # Classifier: [B*P, 16] -> [B*P, 1].\n",
    "        malignancy_logits = self.classifier(z)\n",
    "\n",
    "        # Bethesda score logits: [B*P, 1] -> [B*P, 4].\n",
    "        bethesda_logits = malignancy_logits.repeat(1,4) - self.biases.repeat(malignancy_logits.shape[0], 1)\n",
    "\n",
    "        return malignancy_logits, bethesda_logits\n",
    "\n",
    "\n",
    "class MobileNetV2Model(nn.Module):\n",
    "    \"\"\"MobileNetV2 model class.\n",
    "\n",
    "    Attributes:\n",
    "        biases (torch.nn.Parameter): TODO: add description.\n",
    "        vgg_features (torch.nn.Module): VGG feature map function.\n",
    "        features (torch.nn.Sequential): hidden layers.\n",
    "        classifier (torch.nn.Sequential): classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, params: dict):\n",
    "        \"\"\"MobileNetV2 model class constructor. \n",
    "        \n",
    "        Args:\n",
    "            params (dict): hyperparams.\n",
    "        \"\"\"\n",
    "        super(MobileNetV2Model, self).__init__()\n",
    "        \n",
    "        # Output thresholds for Bethesda score prediction. Selected such that sigmoid(t1)-sigmoid(t2) = sigmoid(t2)-sigmoid(t3) = sigmoid(t3)-sigmoid(t4) = 0.2.\n",
    "        if params['trainable_biases']:\n",
    "            self.biases = nn.Parameter(torch.tensor([1.386, 0.405, -0.405, -1.386]))\n",
    "        else:\n",
    "            self.biases = torch.tensor([1.386, 0.405, -0.405, -1.386],requires_grad=False)\n",
    "        \n",
    "        # Load MobileNetV2 model (without ImageNet pretraining).\n",
    "        mobilenet = models.mobilenet_v2(pretrained=params['pretrain'])\n",
    "        \n",
    "        # Define MobileNetV2 feature extractor.\n",
    "        self.mobilenet_features = mobilenet.features\n",
    "\n",
    "        # Spatial average pooling operation: [B,C=1280,H=4,W=4] -> [B,C=1280,H=1,W=1].\n",
    "        self.avg_pool_2d = torch.nn.AvgPool2d(kernel_size=4)\n",
    "\n",
    "        # Final classifier.\n",
    "        self.classifier = nn.Linear(in_features=1280,out_features=1)        \n",
    "               \n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"VGG11 classifier forward pass.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): [B, P, C, H, W] torch.tensor input. (B=batch, P=patches, CHW=image dims).\n",
    "\n",
    "        Returns:\n",
    "            malignancy_logits: [B*P, 1] float torch.tensor of malignancy logits.\n",
    "            bethesda_logits: [B*P, 4] float torch.tensor of bethesda logits.\n",
    "        \"\"\"\n",
    "        # Reshape input: [B, P, C, H, W] -> [B*P, C, H, W].\n",
    "        z = z.view([z.shape[0]*z.shape[1]] + list(z.shape[2:]))\n",
    "\n",
    "        # Extract mobilenet features: [B*P, C, H, W] -> [B*P, 1280, 4, 4].\n",
    "        z = self.mobilenet_features(z)\n",
    "\n",
    "        # Spatial average pool: [B*P, 1280, 4, 4] -> [B*P, 1280, 1, 1].\n",
    "        z = self.avg_pool_2d(z)\n",
    "\n",
    "        # Reshape: [B*P, 1280, 1, 1] -> [B*P, 1280]\n",
    "        z = z.view(z.shape[0], -1)   \n",
    "\n",
    "        # Classifier: [B*P, 1280] -> [B*P, 1].\n",
    "        malignancy_logits = self.classifier(z)\n",
    "\n",
    "        # Bethesda score logits: [B*P, 1] -> [B*P, 4].\n",
    "        bethesda_logits = malignancy_logits.repeat(1,4) - self.biases.repeat(malignancy_logits.shape[0], 1)\n",
    "\n",
    "        return malignancy_logits, bethesda_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08165319",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'pretrain': 0,\n",
    "          'trainable_biases': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1949e936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/miniconda3/envs/thyroid/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/quan/miniconda3/envs/thyroid/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = VGG11Model(params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a1f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.vgg11_bn(pretrained=1);\n",
    "model = models.mobilenet_v2(pretrained=params['pretrain']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849717c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9cdaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dNormActivation(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (1): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (9): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (10): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (11): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (12): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (13): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (14): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (15): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (16): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (17): InvertedResidual(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (18): Conv2dNormActivation(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f98c37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/miniconda3/envs/thyroid/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize(256),\n",
    "    v2.CenterCrop(224),\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ae68297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('/home/quan/work/thyroid/data/NOH/001.NguyeThiLan- Right/IMG_20221219_101351.jpg')\n",
    "image = test_transform(image)\n",
    "image = image.unsqueeze(0)\n",
    "# image = image.to(device)\n",
    "output = model.features(image)\n",
    "# output = output.argmax(dim=1).cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbb6141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15383994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 7, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9185b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool_2d = torch.nn.AvgPool2d(kernel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b59759",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = avg_pool_2d(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84fe41a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c745a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuanVGG11Model(nn.Module):\n",
    "    \"\"\"VGG11 model class.\n",
    "\n",
    "    Attributes:\n",
    "        biases (torch.nn.Parameter): TODO: add description.\n",
    "        vgg_features (torch.nn.Module): VGG feature map function.\n",
    "        features (torch.nn.Sequential): hidden layers.\n",
    "        classifier (torch.nn.Sequential): classifier.\n",
    "    \"\"\"\n",
    "    def __init__(self, params: dict):\n",
    "        \"\"\"VGG11 model class constructor. \n",
    "        \n",
    "        Args:\n",
    "            params (dict): hyperparameters.\n",
    "        \"\"\"\n",
    "        super(QuanVGG11Model, self).__init__()\n",
    "        \n",
    "        # Output thresholds for Bethesda score prediction. Selected such that sigmoid(t1)-sigmoid(t2) = sigmoid(t2)-sigmoid(t3) = sigmoid(t3)-sigmoid(t4) = 0.2.\n",
    "        if params['trainable_biases']:\n",
    "            self.biases = nn.Parameter(torch.tensor([1.386, 0.405, -0.405, -1.386]))\n",
    "        else:\n",
    "            self.biases = torch.tensor([1.386, 0.405, -0.405, -1.386], requires_grad=False)\n",
    "        \n",
    "        # Load VGG11 model (without ImageNet pretraining).\n",
    "        vgg11 = models.vgg11_bn(pretrained=params['pretrain'])\n",
    "        \n",
    "        # Load VGG11 weights. TODO(dd208): explain where the checkpoint comes from. TODO: Need to uncomment!\n",
    "        # vgg11.load_state_dict(torch.load('../params_soft_link/vgg11_bn-6002323d.pth'))\n",
    "        \n",
    "        # Define VGG11 feature extractor.\n",
    "        self.vgg_features = vgg11.features        \n",
    "        # Further feature extraction.\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4 , 16), #(512, 16)\n",
    "            nn.BatchNorm1d(16), #nn.Dropout(),\n",
    "            nn.ReLU(True))        \n",
    "        # Final classifier. \n",
    "        self.classifier = nn.Sequential( \n",
    "            nn.BatchNorm1d(16), #nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(16, 1))\n",
    "        \n",
    "               \n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"VGG11 classifier forward pass.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): [B, P, C, H, W] torch.tensor input. (B=batch, P=patches, CHW=image dims).\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: _description_\n",
    "        \"\"\"\n",
    "        # Reshape input: [B, P, C, H, W] -> [B*P, C, H, W].\n",
    "        z = z.view([z.shape[0]*z.shape[1]] + list(z.shape[2:]))                              \n",
    "        # Extract VGG features: [B*P, C, H, W] -> [B*P, 512, 4, 4].\n",
    "        z = self.vgg_features(z)     \n",
    "                     \n",
    "        # Reshape: [B*P, 512, 4, 4] -> [B*P, 512*4*4]\n",
    "        z = z.view(z.shape[0], -1)  \n",
    "        # Further feature extraction: [B*P, 512*4*4] -> [B*P, 16].\n",
    "        z = self.features(z)        \n",
    "\n",
    "        # Classifier: [B*P, 16] -> [B*P, 1].\n",
    "        malignancy_logits = self.classifier(z)\n",
    "\n",
    "        # Bethesda score logits: [B*P, 1] -> [B*P, 4].\n",
    "        bethesda_logits = malignancy_logits.repeat(1,4) - self.biases.repeat(malignancy_logits.shape[0], 1)\n",
    "\n",
    "        return malignancy_logits, bethesda_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263202bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG11Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mode1 \u001b[38;5;241m=\u001b[39m \u001b[43mVGG11Model\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VGG11Model' is not defined"
     ]
    }
   ],
   "source": [
    "mode1 = VGG11Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a79a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
